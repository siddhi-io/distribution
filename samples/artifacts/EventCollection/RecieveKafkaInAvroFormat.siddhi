@App:name("ReceiveKafkaInAvroFormat")

@App:description('Receive events via Kafka transport in Avro format and view the output on the console')

/*
Purpose:
    This application demonstrates how to configure Siddhi App to receive events to the SweetProductionStream via Kafka transport in Avro Formatand and and log the events in LowProductionAlertStream to the output console.

Prerequisites:
    1) The following steps must be executed to enable to receive events via the Kafka transport. Since you need to shut down the server to execute these steps, get a copy of these instructions prior to proceeding.
        a) Download the Kafka broker from here: https://archive.apache.org/dist/kafka/0.10.0.0/kafka_2.11-0.10.0.0.tgz
        b) Convert and copy the Kafka client jars from the {KafkaHome}/libs directory to the {Siddhi_Distribution_Home}/libs directory as follows.
              i) Create a directory named {Source} in a preferred location in your machine and copy the following JARs to it from the {KafkaHome}/libs directory.
                 * kafka_2.11-0.10.0.0.jar
                 * kafka-clients-0.10.0.0.jar
                 * metrics-core-2.2.0.jar
                 * scala-library-2.11.8.jar
                 * scala-parser-combinators_2.11-1.0.4.jar
                 * zkclient-0.8.jar
                 * zookeeper-3.4.6.jar
             ii) Create another directory named {Destination} in a preferred location in your machine.
            iii) To convert all the Kafka jars you copied into the {Source} directory, issue the following command,
                 * For Windows: {Siddhi_Distribution_Home}/bin/jartobundle.bat <{Source} Directory Path> <{Destination} Directory Path>
                 * For Linux: sh {Siddhi_Distribution_Home}/bin/jartobundle.sh <{Source} Directory Path> <{Destination} Directory Path>
             iv) Add the OSGI converted kafka libs from {Destination} directory to {Siddhi_Distribution_Home}/lib
              v) Add the original Kafka libs from {Source} to {Siddhi_Distribution_Home}/samples/sample-clients/lib
             vi) Navigate to {KafkaHome} and start zookeeper node using "sh bin/zookeeper-server-start.sh config/zookeeper.properties" command
            vii) Navigate to {KafkaHome} and start Kafka server node using "sh bin/kafka-server-start.sh config/server.properties" command
           viii) Navigate to {Siddhi_Distribution_Home} and start the editor: sh bin/tooling.sh
    2) Save this sample

Executing the Sample:
    1) Start the Siddhi application by clicking on 'Run'
    2) If the Siddhi application starts successfully, the following messages would be shown on the console,
        * ReceiveKafkaInBinaryFormat.siddhi - Started Successfully!

    Notes:
    If you edit this application while it's running, stop the application -> Save -> Start.

Testing the Sample:
    1) kafka-avro-producer client is used to publish avro recoreds in to kafaka.
       Navigate to {Siddhi_Distribution_Home}/samples/sample-clients/kafka-producer and run "ant" command as follows:
        ant -DnoOfEventsToSend=5 -DtopicName='sample_kafka_avro_topic' -Dtype=avro -DisBinaryMessage=true

Viewing the Results:
    Messages similar to the following would be shown on the console.

    [2019-09-23_21-07-06_170] INFO {io.siddhi.core.stream.output.sink.LogSink} - ReceiveKafkaInAvroFormat : LowProductionAlertStream : Event{timestamp=1569253026170, data=[Cream Sandwich, 5821.74], isExpired=false}

    Note:
    Stop this Siddhi application, once you are done with the execution.
    Stop Kafka server and Zookeeper server individually by executing Ctrl+C.
*/

@source(type='kafka',
        topic.list='sample_kafka_avro_topic',
        partition.no.list='0',
        threading.option='single.thread',
        group.id='group',
        is.binary.message='true',
        bootstrap.servers='localhost:9092',
        @map(type='avro', schema.def = """{"type":"record","name":"sweetProduction","namespace":"material","fields":[{"name":"name","type":"string"}, {"name":"amount","type":"double"}]}""",@attributes(name="name",amount="amount")))
define stream SweetProductionStream(name string, amount double);

@sink(type='log')
define stream LowProductionAlertStream(name string, amount double);

@info(name='outputQuery')
from SweetProductionStream
select *
insert into LowProductionAlertStream;